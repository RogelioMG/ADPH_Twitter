{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor: Rogelio Martínez Gutierréz\n",
    "Fecha: 07/07/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos las librerías necesarias, en este caso son Twython, Pandas y csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al registrarse como Twitter developer y haber calificado, obtendremos una API_KEY y CUSTOMER_KEY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'z5zA30mP0tnu6QxYZQKmAOYd2'\n",
    "API_SECRET = 'JTqIVp7oQOeo8oXhWuQWW8f9Z6dmxCihT19wLThIyB8keNQT0W'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las claves que nos proporciona Twitter, solicitamos un TOKEN para hacer consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter1 = Twython(API_KEY, API_SECRET, oauth_version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el TOKEN en un archivo para posteriormente usarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAAAAAAAAAAAAAAAAAAAABj72AAAAAAAfPxUOl4iLq9dwUnt8NT%2Bl90JHIE%3DdWlzOqQdxFkD0DhsXqruR16jD4cq5lzx6ULqchSaFgBd6LTLEq'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACCESS_TOKEN = twitter1.obtain_access_token()\n",
    "ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si creamos una instancia que nos permitirá para hacer consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter2 = Twython(API_KEY, access_token=ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso yo voy a hacer una consulta del #FelizMartes, en español, con resultados mezclados y solicitare 100 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = twitter2.search(q='#FelizMartes', lang='es', result_type='mixed', count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La consulta nos arroja un diccionario como resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)\n",
    "type(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El diccionario contiene dos datos, 'statuses' y 'search_metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['statuses', 'search_metadata'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos estos datos y los asignamos a dos nuevas listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "info=tweets['search_metadata']\n",
    "estado=tweets['statuses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minería de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT=0 #contador\n",
    "listaH =[] #Lista que almacenara Hashtags por tweet\n",
    "while CT < 100:\n",
    "    tw = estado [CT]\n",
    "    tw2 = tw['entities']\n",
    "    tw3 = tw2['hashtags']\n",
    "    listaH. append(tw3) \n",
    "    CT += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CT2=0 #contador\n",
    "lista_HF=[] #Lista que almacena todos los Hashtags\n",
    "lista_D=[] #lista de listas de hashtags\n",
    "while CT2 < 100:\n",
    "    lista1 = listaH[CT2] \n",
    "    TamT = len(lista1) #numero de hashtag por tweet\n",
    "    lista_V=[] #lista que funciona como variable\n",
    "    if TamT > 0:\n",
    "        CT3 = 0 #contador\n",
    "        while CT3  != TamT :\n",
    "            lista2 = lista1[CT3]\n",
    "            lista3 = lista2['text']\n",
    "            lista_HF. append(lista3)\n",
    "            lista_V. append(lista3)\n",
    "            CT3 += 1\n",
    "    CT2 += 1\n",
    "    lista_D. append(lista_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodo=set(lista_HF) #conjunto con todos los hashtags\n",
    "DicNodos = dict(zip(nodo, range(len(nodo)))) #Diccionario con los nodos y un id\n",
    "TamD = len(lista_D) #Tamaño de la lista de listas\n",
    "nodos_n=[] # Lista de listas de nodos por su id\n",
    "CT4=0 #contador\n",
    "while CT4 < TamD:\n",
    "    lista_D2=lista_D[CT4] \n",
    "    TamD2=len(lista_D2) #numero de hashtag por tweet\n",
    "    nodos_n1=[] #lista que funciona como variable\n",
    "    if TamD2 > 0:\n",
    "        CT5=0 #contador\n",
    "        while CT5 != TamD2:\n",
    "            nodos_n1. append(DicNodos[lista_D2[CT5]])\n",
    "            CT5 += 1\n",
    "    CT4 += 1\n",
    "    nodos_n. append(nodos_n1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escritura de datos en archivos \".csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('enlaces.csv','w', newline='') as csvfile:\n",
    "    fieldnames=['origen','destino']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for tweet in nodos_n:\n",
    "        for hashtag in tweet:\n",
    "            origen = hashtag\n",
    "            destinos = tweet\n",
    "            destinos.remove(origen)\n",
    "            for d in destinos:\n",
    "                writer.writerow({'origen': origen,'destino': d})\n",
    "                writer.writerow({'origen': d,'destino': origen})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('nodos.csv','w',newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(DicNodos.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
